# Spatial cross-validation {#spatial-cv}

## Prerequisites {-}

This chapter requires a strong grasp of spatial data analysis and processing, covered in chapters \@ref(spatial-class) to \@ref(transform).
You should also be familiar with linear regression and its generalized extensions [e.g. @zuur_mixed_2009].

The chapter uses the following packages:

```{r, message = FALSE} 
library(sf)
library(raster)
library(RQGIS)
library(RSAGA)
library(mlr)
```

- Required data will be downloaded in due course.

## Introduction

Section \@ref(software-for-geocomputation) mentioned several programming languages suitable for command-line based geocomputation.
The advantages of geocomputation with R were discussed, including its unparalleled statistical power.
This chapter makes use of some of this statistical power, by demonstrating methods for predictive mapping by means of statistical learning [@james_introduction_2013].
The focus is the use of spatial cross-validation (or 'spatial CV' for short, a term we will define shortly) to assess model performance and reduce spatial bias.
Spatial CV is an excellent example of using statistical methods to model spatial data and, at the time of writing, the technique is better supported in R than any other language.

Statistical learning aims at understanding data by building models which disentangle underlying relationships.
Statistical learning can be roughly grouped into supervised and unsupervised techniques, both of which are used throughout a vast range of disciplines such as economics, physics, medicine, biology, ecology and geography [@james_introduction_2013].
In this chapter we will focus on supervised techniques, i.e., we have a response variable, in our case this will be a binary one (landslide vs. non-landslide) but could be also a numeric (pH value), an integer (species richness) or a categorical variable (land use).
Supervised techniques such as regression and machine learning model the relationship between the response variable and various predictors.
Using regression or machine learning models depends on the aim: statistical inference or prediction.
Regression techniques are especially useful if the aim is statistical inference, i.e. if we are interested if a predictor significantly contributes to a model and how much.
To trust the model outcomes we need to perform a throrough model validation testing if one or several of the underlying model assumptions (heterogeneity, indepedence, etc.) have been violated [@zuur_mixed_2009].
By contrast, machine learning approaches are especially appealing due to their lack of assumptions.
Though statistical inference is impossible [@james_introduction_2013], various studies have shown that machine learning outperform regression techniques with regard to predictive performance [@schratz_performance_2018]. <!-- add one more source -->
Naturally, with the advent of big data, machine learning has even gained in popularity since frequently the underlying relationship between variables is less important than the prediction such as future customer behavior.

Though prediction will be the aim of the modeling in this chapter, we will not use machine learning but a simple generalized linear model (GLM).^[Nevertheless, a generalized additive model or a machine learning approach would be more suitable for our dataset (see exercises).
We will show in chapter \@ref(eco) how to use spatial cross-validation with a machine learning approach.]
This is because we can use also regression techniques such as a GLM without having to worry too much about possible model misspecfications when the aim is prediction.
Additionally, GLMs are probably familiar to most readers, and therefore instead of explaining in detail the model building we can focus on the speciality of geographic data in a modeling context and spatial cross-validation.^[Readers who are in need of refreshing their regression skills might have a look at @zuur_mixed_2009.]

Cross-validation determines a model's ability to predict new data or differently put its ability to generalize.
To achieve this, cross-validation splits a dataset into a test and a training dataset.
It uses the training data to fit the model, and applies the learned relationship to the test data thereby checking if the model is able to predict the correct result.
Basically, cross-validation helps to detect over-fitting since a model that fits too closely the training data and its specific pecularities (noise, random fluctuations) will have a bad prediction performance on the test data.
However, the basic requirement for this is, that the test data is indepedent of the trainig data.
Cross-validation achieves this by splitting the data randomly into test and training sets. 
However, randomly splitting spatial data results in the fact that training points are frequently located next to test points.
Since points close to each other are more similar compared to points further away, test and training datasets might not be independent.
The consequence is that cross-validation would fail to detect overfitting in the presence of spatial autocorrelation.
Here, spatial cross-validation will come to the rescue which will be the main topic of this chapter.

## Case study: landslide susceptibility {#case-study}

For more details please refer to @muenchow_geomorphic_2012.

```{r, echo=FALSE, fig.cap="Landslide initiation points (red) and points unaffected by landsliding (blue) in Southern Ecuador. Randomly selected test points are marked by a golden border. Projection: UTM zone 17S (EPSG: 32717)."}
library(tmap)
load("extdata/spatialcv.Rdata")
lsl = st_as_sf(lsl, coords = c("x", "y"), crs = 32717)
hs = hillShade(ta$slope * pi / 180, terrain(dem, opt = "aspect"))
rect = tmaptools::bb_sp(hs)
bbx = tmaptools::bb(hs, xlim = c(-0.02, 1), ylim = c(-0.02, 1), relative = TRUE)
# random sample 20%
ind = sample(1:nrow(lsl), round(nrow(lsl) * 0.2))
sam = lsl[ind, ]

tm_shape(hs, bbox = bbx) +
	tm_grid(col = "black", n.x = 1, n.y = 1, labels.inside.frame = FALSE,
	        labels.rot = c(0, 90)) +
	tm_raster(palette = gray(0:100 / 100), n = 100, legend.show = FALSE) +
	tm_shape(dem) +
	tm_raster(alpha = 0.5, palette = terrain.colors(10),
	          auto.palette.mapping = FALSE, legend.show = FALSE) +
	tm_shape(lsl) + 
	tm_bubbles("lslpts", size = 0.5, palette = "-RdYlBu") +
  tm_shape(sam) +
  tm_bubbles(border.col = "gold", border.lwd = 2, alpha = 0, size = 0.5) +
	qtm(rect, fill = NULL) +
	tm_layout(outer.margins = c(0.04, 0.04, 0.02, 0.02), frame = FALSE)
```


## Spatial cross-validation

i.e. the fact that points close to each other tend to share similarities compared to points further apart.
Simply put, if it rains at one location it is pretty likely that it also rains if we moved 1 meter in any direction.
But if we moved 10 or 100 km this might not longer be the case. 


- short intro spatial autocorrelation, maybe by showing artificial spatial datasets with different sills, nuggets, ranges (don't show the code but just the concept of spatial autocorrelation)
- spatial cross-validation when predictive performance is desirable 
- use Ecuador landslide data to spatially predict landslide susceptibility (GAM, i.e. a semiparametric extension of a GLM + refer to eco chapter in which we will use ml and where the hyperparameter tuning also requires an additional inner-fold tuning)

@muenchow_geomorphic_2012
@brenning_spatial_2012
@schratz_performance_2018
@james_introduction_2013
@blangiardo_spatial_2015
@zuur_beginners_2017
@zuur_mixed_2009

- What is spatial modeling and for what do we use it?
- What is cross-validation, why do we need it?
- What is spatial cv?

Spatial modeling: species distribution models, landslide susceptibility, epidemiology, disease mapping, rock glaciers, etc.

When we are interested in the accuracy of a model, i.e., when we want to assess a model's predictive performance, we want to avoid overfitting.^[short definition of overfitting]
Spatial autocorrelation will lead to overfitting when the training dataset is not independent of the test dataset which is frequently the case in temporal and spatial settings.

Cross-validation separates test and training datasets randomly.
Let's take our landslide dataset as an example.
Randomly selecting 20% of all points leads to an unwanted effect, namely that test and training points might be close to each other (see Figure ??).
The first law of geography states that points close to each other tend to be, on average, more similar compared to points further apart.
This means these points are not indepedent.
Hence, using this information in our modeling is like a sneak preview, i.e. using information that should be unavailable to the test dataset.

<!--
Usually people seek to accomplish one of the following aims when using supervised statistical learning techniques: 

1. Spatial prediction of the response variable
2. Inference about the relationship between response and predictors

In the latter case, we need to make sure to comply with all model assumptions (normality, heterogeneity, independence).
Spatial predictions are easier since we can argue that, the predictive performance of a model incorporating a (spatial) correlation structure is on average the same as for a model without a spatial correlation structure.
This is the reason why machine learning techniques (no explicit model assumptions) are so popular when the goal is a good prediction.
-->

## Exercises
