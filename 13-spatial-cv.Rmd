# Spatial cross-validation {#spatial-cv}

## Prerequisites {-}

This chapter requires a strong grasp of spatial data analysis and processing, covered in chapters \@ref(spatial-class) to \@ref(transform).
You should also be familiar with linear regression and its generalized extensions [e.g. @zuur_mixed_2009;@james_introduction_2013].

The chapter uses the following packages:

```{r, message = FALSE} 
library(sf)
library(raster)
library(RQGIS)
library(RSAGA)
library(mlr)
```

- Required data will be downloaded in due course.

## Introduction

Section \@ref(software-for-geocomputation) mentioned several programming languages suitable for command-line based geocomputation.
The advantages of geocomputation with R were discussed, including its unparalleled statistical power.
This chapter makes use of some of this statistical power, by demonstrating methods for predictive mapping by means of statistical learning [@james_introduction_2013].
The focus is the use of spatial cross-validation (or 'spatial CV' for short, a term we will define shortly) to assess model performance and reduce spatial bias.
Spatial CV is an excellent example of using statistical methods to model spatial data and, at the time of writing, the technique is better supported in R than any other language.

Statistical learning aims at understanding data by building models which disentangle underlying relationships.
Statistical learning can be roughly grouped into supervised and unsupervised techniques, both of which are used throughout a vast range of disciplines such as economics, physics, medicine, biology, ecology and geography [@james_introduction_2013].
In this chapter we will focus on supervised techniques, i.e., we have a response variable, in our case this will be a binary one (landslide vs. non-landslide occurence) but could be also a numeric (pH value), an integer (species richness) or a categorical variable (land use).
Supervised techniques such as regression and machine learning model the relationship between the response variable and various predictors.
Using either regression or machine learning techniques depends on the aim: statistical inference or prediction.
Regression techniques are especially useful if the aim is statistical inference, i.e. if we are interested if a predictor significantly contributes to a model and how much.
To trust the model outcomes we need to perform a thorough model validation testing if one or several of the underlying model assumptions (heterogeneity, independence, etc.) have been violated [@zuur_mixed_2009].
By contrast, machine learning approaches are especially appealing due to their lack of assumptions.
Though statistical inference is impossible [@james_introduction_2013], various studies have shown that machine learning outperform regression techniques with regard to predictive performance [@schratz_performance_nodate]. <!-- add one more source -->
Naturally, with the advent of big data, machine learning has even gained in popularity since frequently the underlying relationship between variables is less important than the prediction such as future customer behavior.

Though prediction will be the aim of the modeling in this chapter, we will not use machine learning but a simple generalized linear model (GLM).^[Nevertheless, a generalized additive model or a machine learning approach would be more suitable for our dataset (see exercises).
We will show in chapter \@ref(eco) how to use spatial cross-validation with a machine learning approach.]
This is because we can use also regression techniques such as a GLM without having to worry too much about possible model misspecifications when the aim is prediction.
Additionally, GLMs are probably familiar to most readers, and therefore instead of explaining in detail the model building we can focus on the speciality of geographic data in a modeling context and spatial CV.^[Readers who are in need of refreshing their regression skills might have a look at @zuur_mixed_2009 and @james_introduction_2013, respectively.]

CV determines a model's ability to predict new data or differently put its ability to generalize.
To achieve this, CV splits a dataset into a test and a training dataset.
It uses the training data to fit the model, and checks if the trained model is able to predict the correct results for the test data.
Basically, cross-validation helps to detect over-fitting since a model that fits too closely the training data and its specific peculiarities (noise, random fluctuations) will have a bad prediction performance on the test data.
However, the basic requirement for this is, that the test data is independent of the training data.
CV achieves this by splitting the data randomly into test and training sets. 
However, randomly splitting spatial data results in the fact that training points are frequently located next to test points.
Since points close to each other are more similar compared to points further away, test and training datasets might not be independent.
The consequence is that cross-validation would fail to detect overfitting in the presence of spatial autocorrelation.
Here, spatial CV will come to the rescue which will be the main topic of this chapter.

## Case study: landslide susceptibility {#case-study}

To introduce spatial CV by example, we will use a landslide dataset from Southern Ecuador.
For a detailed description of the dataset and the study area please refer to @muenchow_geomorphic_2012.
One can find a subset of the corresponding data in the **RSAGA** package.
The following command loads two datasets, a `data.frame` named `landslides` and a `list` named `dem`.

```{r, eval = FALSE}
data("landslides", package = "RSAGA")
```

`landslides` contains a boolean column `lslpts` where `TRUE` corresponds to an observed landslide initiation point and `FALSE` to points where no landsliding occurred. 
Columns `x` and `y` contain the corresponding coordinates.
The landslide initation point is located in the scarp of a landslide polygon.
The coordinates for the non-landslide points were sampled randomly with the restriction to fall outside of the slightly buffered landslide polygons.
`summary(landslides$lslpts)` tells us that 175 landslide points where observed while we have 1360 non-landslide points.
To make the ratio between landslide and non-landslide points more balanced, we randomly sample 175 from the 1360 non-landslide points.

```{r, eval = FALSE}
non = landslides[landslides$lslpts == FALSE, ]
ind = sample(1:nrow(non), nrow(landslides[landslides$lslpts == TRUE, ]))
lsl = rbind(non[ind, ], landslides[landslides$lslpts == TRUE, ])
```

`dem` is in fact a digital elevation model and consists of two list elements with the first being a raster header and the second being a matrix containing the altitudinal values.
To transform this list into a `raster`, we can write:

```{r, eval = FALSE}
dem = 
  raster(dem$data, 
         crs = "+proj=utm +zone=17 +south +datum=WGS84 +units=m +no_defs",
         xmn = dem$header$xllcorner, 
         xmx = dem$header$xllcorner + dem$header$ncols * dem$header$cellsize,
         ymn = dem$header$yllcorner,
         ymx = dem$header$yllcorner + dem$header$nrows * dem$header$cellsize)
```

To model the probability for landslide occurrence, we need some predictors.
Here, we use selected terrain attributes frequently associated with landsliding [@muenchow_geomorphic_2012], all of which can be computed from the provided digital elevation model (`dem`) using R-GIS bridges (see Chapter \@ref(gis)).
We leave it as an exercise to the reader to compute the terrain attribute rasters and extract the corresponding values to our landslide/non-landslide dataframe (see also exercises).
The first three rows of the resulting dataframe (still named `lsl`) could look like this:

<!-- has anybody an idea why I have to run the following code chunk two times to make it work when rendering the book with `bookdown::render_book()`?-->
```{r, echo=FALSE}
load("extdata/spatialcv.Rdata")
```

```{r, echo=FALSE}
load("extdata/spatialcv.Rdata")
```

```{r}
head(lsl, 3)
```

The added columns are:

- `slope`: slope angle (°)
- `cplan`: plan curvature (rad m^−1^) expressing the convergence or divergence of a slope and thus water flow.
- `cprof`: profile curvature (rad m^-1^) as a measure of flow acceleration, also known as downslope change in slope angle 
- `elev`: elevation (m a.s.l.) as the representation of different altitudinal zones of vegetation and precipitation in the study area.
- `log_carea`: the decadic logarithm of the catchment area (log m^2^) representing the amount of water flowing towards a location.


```{r, echo=FALSE, fig.cap="Landslide initiation points (red) and points unaffected by landsliding (blue) in Southern Ecuador. Randomly selected test points are marked by a golden border. Projection: UTM zone 17S (EPSG: 32717)."}
library(tmap)
lsl_sf = st_as_sf(lsl, coords = c("x", "y"), crs = 32717)
hs = hillShade(ta$slope * pi / 180, terrain(ta$elev, opt = "aspect"))
rect = tmaptools::bb_poly(hs)
bbx = tmaptools::bb(hs, xlim = c(-0.02, 1), ylim = c(-0.02, 1), relative = TRUE)
# random sample 20%
ind = sample(1:nrow(lsl_sf), round(nrow(lsl_sf) * 0.2))
sam = lsl_sf[ind, ]

tm_shape(hs, bbox = bbx) +
	tm_grid(col = "black", n.x = 1, n.y = 1, labels.inside.frame = FALSE,
	        labels.rot = c(0, 90)) +
	tm_raster(palette = gray(0:100 / 100), n = 100, legend.show = FALSE) +
	tm_shape(ta$elev) +
	tm_raster(alpha = 0.5, palette = terrain.colors(10),
	          auto.palette.mapping = FALSE, legend.show = FALSE) +
	tm_shape(lsl_sf) + 
	tm_bubbles("lslpts", size = 0.5, palette = "-RdYlBu") +
  tm_shape(sam) +
  tm_bubbles(border.col = "gold", border.lwd = 2, alpha = 0, size = 0.5) +
	qtm(rect, fill = NULL) +
	tm_layout(outer.margins = c(0.04, 0.04, 0.02, 0.02), frame = FALSE)
```


## Introduction to spatial CV

figure showing difference between spatial and non-spatial random sampling
cross-reference **sperrorest** which has been integrated into **mlr**

## Modeling and spatial CV with **mlr**
In R there are literally hundreds of packages available for statistical learning (e.g., have a look at the [CRAN task machine learning](https://CRAN.R-project.org/view=MachineLearning)).
Many of them come with their own interface which is why programmers frequently have to spend a lot of time to figure out the specifics of each of these packages or how to compare modeling results from different packages.
The **mlr** package acts as a meta- or umbrella-package providing a unified interface to all popular statistical learning techniques available in R including classification, regression, survival analysis and clustering.^[As pointed out in the beginning we will solely focus on supervised learning techniques in this chapter.]
The standardized **mlr** interface is based on so-called basic building blocks (see \@ref(fig:building-blocks)).

<!-- @Jakub: yes, I will ask if we me may use the figure -->
```{r building-blocks, echo=FALSE,fig.cap="Basic building blocks of the **mlr** package. Figure was taken from http://openml.github.io/articles/slides/useR2017_tutorial/slides_tutorial_files/ml_abstraction-crop.png."}
knitr::include_graphics("http://openml.github.io/articles/slides/useR2017_tutorial/slides_tutorial_files/ml_abstraction-crop.png")
```

First, we need to create a task containing the data, specifically the response and predictor variables, for the model and the model type (such as regression or classification).
Secondly, a learner defines the specific model that models the task data or differently put learns a structure inherent in the provided data.
Thirdly, we assess the predictive performance of the model, i.e. the model's ability to generalize the learned relationship to new data (repetitive resampling).

To put it into practice, we create a task using our landslide data.
Since we have a binary response, we will make use of the classification task, namely `makeClassifTask()`.^[In the case of a regression problem, we would use `makeRegrTask()`.
Type `?makeClassifTask` to find out about all available modeling tasks.
]
First, we specifiy the data which will be used.
The `target` parameter expects the response variable and the `positive` parameter determines which of the two factor levels of the response variable indicates the landslide initiation point.
All other variables of the provided dataset will serve as predictors (check out with `getTaskFormula(task)`).
As we will perform a spatial CV later on, we need to specify the coordinates which will form the basis of the spatial partioning.
These have to be provided in an additional dataframe in `coordinates`. 

```{r}
# separate data to be modeled and coordinates
coords = lsl[, c("x", "y")]
data = dplyr::select(lsl, -x, -y)
# create task
task = makeClassifTask(data = data, target = "lslpts",
                       positive = "TRUE", coordinates = coords)
```

`makeLearner()` determines the statistical learning method to use.
All classification learners start with `classif.` and all regression learners with `regr.` (see `?makeLearners` for more details). 
`listLearners()` helps to find out about all available learners and from which package **mlr** imports them. 
For a specific task, we can run:

```{r, warning=FALSE}
lrns = listLearners(task)
head(lrns[, 1:4])
```

This yields all learners able to model two-class problems (landslide yes or no).
We opt for the binomial classification method from the **stats** package implemented in **mlr** as `classif.binomial`.
Additionally, we have to specify the link-function.
We choose the `logit` link which is also the default when using the `binomial` family in `glm`.
`predict.type` determines the type of the prediction with
<!--Setting it to `response` produces class labels as output, which would be in our case `TRUE` or `FALSE`.-->
 `prob` resulting in a predicted probability for landslide occurrence between 0 and 1.^[Note that this corresponds to `type = response` in `predict.glm`.]

```{r}
lrn = makeLearner(cl = "classif.binomial",
                  link = "logit",
                  predict.type = "prob",
                  fix.factors.prediction = TRUE)
# run the following lines to find out from which package the learner is taken
# and how to access the corresponding help file(s)
# getLearnerPackages(learner)
# helpLearner(learner)
```

Having specified a learner and a task, we can train our model. 


```{r}
mod = train(learner = lrn, task = task)
mlr_fit = getLearnerModel(mod)
```

```{r, eval = FALSE, echo = FALSE}
getTaskFormula(task)
getTaskData(task)
getLearnerModel(mod)
mod$learner.model
```

`getLearnerModel()` extracts the used model which shows that **mlr** passed all specified parameters to the `glm` function in the background as also proved by following code:

```{r}
fit = glm(lslpts ~ ., family = binomial(link = "logit"), data = data)
identical(fit$coefficients, mlr_fit$coefficients)
```

In the beginning, it might seem a bit tedious to learn the **mlr** interface for modeling.
But remember that one only has to learn one single interface to run `r nrow(listLearners())` learners.
Additionally, resampling in **mlr** is really easy and only requires two more steps.
The first thing to to is specifying a resampling method.
Spatial repeated cross-validation

```{r}
resampling = makeResampleDesc(method = "SpRepCV", folds = 5, reps = 10)
```

Executing the resampling method and set the preferred performance measure.

```{r, warning=FALSE, message=FALSE}
set.seed(02192018)
sp_cv = mlr::resample(learner = lrn, task = task, resampling = resampling, 
                      measures = auc)
sp_cv$measures.test$auc
# the same as:
mean(sp_cv$measures.test$auc)
```

To put it into perspective, we compare this result with that of a non-spatial cross-validation.

```{r, echo=FALSE}
# boxplots
# find out if doing a non-spatial cv uses the same folds as the spatial cv...
```

i.e. the fact that points close to each other tend to share similarities compared to points further apart.
Simply put, if it rains at one location it is pretty likely that it also rains if we moved 1 meter in any direction.
But if we moved 10 or 100 km this might not longer be the case. 

- short intro spatial autocorrelation, maybe by showing artificial spatial datasets with different sills, nuggets, ranges (don't show the code but just the concept of spatial autocorrelation)


@muenchow_geomorphic_2012
@brenning_spatial_2012
@james_introduction_2013
@blangiardo_spatial_2015
@zuur_beginners_2017
@zuur_mixed_2009

- What is spatial modeling and for what do we use it?
- What is cross-validation, why do we need it?
- What is spatial cv?

Spatial modeling: species distribution models, landslide susceptibility, epidemiology, disease mapping, rock glaciers, etc.

When we are interested in the accuracy of a model, i.e., when we want to assess a model's predictive performance, we want to avoid overfitting.^[short definition of overfitting]
Spatial autocorrelation will lead to overfitting when the training dataset is not independent of the test dataset which is frequently the case in temporal and spatial settings.

Cross-validation separates test and training datasets randomly.
Let's take our landslide dataset as an example.
Randomly selecting 20% of all points leads to an unwanted effect, namely that test and training points might be close to each other (see Figure ??).
The first law of geography states that points close to each other tend to be, on average, more similar compared to points further apart.
This means these points are not independent.
Hence, using this information in our modeling is like a sneak preview, i.e. using information that should be unavailable to the test dataset.

## Exercises

1. Compute the terrain attributes slope, plan curvature, profile curvature and catchment area from `dem` (provided by `data("landslides", package = "RSAGA")`) with the help of R-GIS bridges, and extract the values from the corresponding output rasters to landslides/non-landslides dataframe.
1. Reproduce the spatial prediction with the derived terrain attribute rasters (see Figure ??).
1. Compute a non-spatial cross-validation and make boxplots to compare the AUROC from a spatial and a non-spatial cv (see also Figure ??).
1. Use the squared slope as a further predictor.
Repeat the modeling. 
How has the spatially cross-validaded mean AUROC value changed compared to the model without the squared altitude predictor?

