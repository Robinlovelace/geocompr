# Spatial cross-validation {#spatial-cv}

## Prerequisites {-}

This chapter requires a strong grasp of spatial data analysis and processing, covered in chapters \@ref(spatial-class) to \@ref(transform).
You should also be familiar with linear regression and its generalized extensions [e.g. @zuur_mixed_2009;@james_introduction_2013].

The chapter uses the following packages:

```{r, message = FALSE} 
library(sf)
library(raster)
library(RQGIS)
library(RSAGA)
library(mlr)
```

- Required data will be downloaded in due course.

## Introduction

Section \@ref(software-for-geocomputation) mentioned several programming languages suitable for command-line based geocomputation.
The advantages of geocomputation with R were discussed, including its unparalleled statistical power.
This chapter makes use of some of this statistical power, by demonstrating methods for predictive mapping by means of statistical learning [@james_introduction_2013].
The focus is the use of spatial cross-validation (or 'spatial CV' for short, a term we will define shortly) to assess model performance and reduce spatial bias.
Spatial CV is an excellent example of using statistical methods to model spatial data and, at the time of writing, the technique is better supported in R than any other language.

Statistical learning aims at understanding data by building models which disentangle underlying relationships.
Statistical learning can be roughly grouped into supervised and unsupervised techniques, both of which are used throughout a vast range of disciplines such as economics, physics, medicine, biology, ecology and geography [@james_introduction_2013].
In this chapter we will focus on supervised techniques, i.e., we have a response variable, in our case this will be a binary one (landslide vs. non-landslide occurence) but could be also a numeric (pH value), an integer (species richness) or a categorical variable (land use).
Supervised techniques such as regression and machine learning model the relationship between the response variable and various predictors.
Using either regression or machine learning techniques depends on the aim: statistical inference or prediction.
Regression techniques are especially useful if the aim is statistical inference, i.e. if we are interested if a predictor significantly contributes to a model and how much.
To trust the model outcomes we need to perform a thorough model validation testing if one or several of the underlying model assumptions (heterogeneity, independence, etc.) have been violated [@zuur_mixed_2009].
By contrast, machine learning approaches are especially appealing due to their lack of assumptions.
Though statistical inference is impossible [@james_introduction_2013], various studies have shown that machine learning outperform regression techniques with regard to predictive performance [@schratz_performance_2018]. <!-- add one more source -->
Naturally, with the advent of big data, machine learning has even gained in popularity since frequently the underlying relationship between variables is less important than the prediction such as future customer behavior.

Though prediction will be the aim of the modeling in this chapter, we will not use machine learning but a simple generalized linear model (GLM).^[Nevertheless, a generalized additive model or a machine learning approach would be more suitable for our dataset (see exercises).
We will show in chapter \@ref(eco) how to use spatial cross-validation with a machine learning approach.]
This is because we can use also regression techniques such as a GLM without having to worry too much about possible model misspecifications when the aim is prediction.
Additionally, GLMs are probably familiar to most readers, and therefore instead of explaining in detail the model building we can focus on the speciality of geographic data in a modeling context and spatial CV.^[Readers who are in need of refreshing their regression skills might have a look at @zuur_mixed_2009 and @james_introduction_2013, respectively.]

CV determines a model's ability to predict new data or differently put its ability to generalize.
To achieve this, CV splits a dataset into a test and a training dataset.
It uses the training data to fit the model, and applies the learned relationship to the test data thereby checking if the model is able to predict the correct result.
Basically, cross-validation helps to detect over-fitting since a model that fits too closely the training data and its specific peculiarities (noise, random fluctuations) will have a bad prediction performance on the test data.
However, the basic requirement for this is, that the test data is independent of the training data.
CV achieves this by splitting the data randomly into test and training sets. 
However, randomly splitting spatial data results in the fact that training points are frequently located next to test points.
Since points close to each other are more similar compared to points further away, test and training datasets might not be independent.
The consequence is that cross-validation would fail to detect overfitting in the presence of spatial autocorrelation.
Here, spatial CV will come to the rescue which will be the main topic of this chapter.

## Case study: landslide susceptibility {#case-study}

To introduce spatial CV by example, we will use a landslide dataset from Southern Ecuador.
For a detailed description of the dataset and the study area please refer to @muenchow_geomorphic_2012.
One can find a subset of the corresponding data in the **RSAGA** package.
The following command loads two datasets, a `data.frame` named `landslides` and a `list` named `dem`.

```{r, echo = FALSE}
data("landslides", package = "RSAGA")
```

`landslides` contains a boolean column `lslpts` where `TRUE` corresponds to an observed landslide initiation point and `FALSE` to points where no landsliding occurred. 
Columns `x` and `y` contain the corresponding coordinates.
The landslide initation point is located in the scarp of a landslide polygon.
The coordinates for the non-landslide points were sampled randomly with the restriction to fall outside of the slightly buffered landslide polygons.
`summary(landslides$lslpts)` tells us that 175 landslide points where observed while we have 1360 non-landslide points.
To make the ratio between landslide and non-landslide points more balanced, we randomly sample 175 from the 1360 non-landslide points.

```{r, echo = FALSE}
non = landslides[landslides$lslpts == FALSE, ]
ind = sample(1:nrow(non), nrow(landslides[landslides$lslpts == TRUE, ]))
lsl = rbind(non[ind, ], landslides[landslides$lslpts == TRUE, ])
```

`dem` is in fact a digital elevation model and consists of two list elements with the first being a raster header and the second being a matrix with the altitudinal values.
To transform the list into a `raster`, we can write:

```{r, eval = FALSE}
dem = 
  raster(dem$data, 
         crs = "+proj=utm +zone=17 +south +datum=WGS84 +units=m +no_defs",
         xmn = dem$header$xllcorner, 
         xmx = dem$header$xllcorner + dem$header$ncols * dem$header$cellsize,
         ymn = dem$header$yllcorner,
         ymx = dem$header$yllcorner + dem$header$nrows * dem$header$cellsize)

```

To model the probability for landslide occurrence, we need some predictors.
Here, we use selected terrain attributes frequently associated with landsliding (add references), all of which can be computed from the provided digital elevation model (`dem`) using R-GIS bridges (see Chapter \@ref(gis)).
We leave it as an exercise to the reader to compute the terrain attribute rasters and extract the corresponding values to our landslide/non-landslide dataframe (see also exercises).
The first three rows of the resulting dataframe (still named `lsl`) could look like this:

```{r, include = FALSE}
load("extdata/spatialcv.Rdata")
```

```{r}
head(lsl, 3)
```

The added columns are:

- `slope`: slope angle (°)
- `cplan`: plan curvature (rad m^−1^) expressing the convergence or divergence of a slope and thus water flow.
- `cprof`: profile curvature (rad m^-1^) as a measure of flow acceleration, also known as downslope change in slope angle 
- `elev`: elevation (m a.s.l.) as the representation of different altitudinal zones of vegetation and precipitation in the study area.
- `log_carea`: the decadic logarithm of the catchment area (log m^2^) representing the amount of water flowing towards a location.


```{r, echo=FALSE, fig.cap="Landslide initiation points (red) and points unaffected by landsliding (blue) in Southern Ecuador. Randomly selected test points are marked by a golden border. Projection: UTM zone 17S (EPSG: 32717)."}
library(tmap)
load("extdata/spatialcv.Rdata")
lsl = st_as_sf(lsl, coords = c("x", "y"), crs = 32717)
hs = hillShade(ta$slope * pi / 180, terrain(dem, opt = "aspect"))
rect = tmaptools::bb_poly(hs)
bbx = tmaptools::bb(hs, xlim = c(-0.02, 1), ylim = c(-0.02, 1), relative = TRUE)
# random sample 20%
ind = sample(1:nrow(lsl), round(nrow(lsl) * 0.2))
sam = lsl[ind, ]

tm_shape(hs, bbox = bbx) +
	tm_grid(col = "black", n.x = 1, n.y = 1, labels.inside.frame = FALSE,
	        labels.rot = c(0, 90)) +
	tm_raster(palette = gray(0:100 / 100), n = 100, legend.show = FALSE) +
	tm_shape(dem) +
	tm_raster(alpha = 0.5, palette = terrain.colors(10),
	          auto.palette.mapping = FALSE, legend.show = FALSE) +
	tm_shape(lsl) + 
	tm_bubbles("lslpts", size = 0.5, palette = "-RdYlBu") +
  tm_shape(sam) +
  tm_bubbles(border.col = "gold", border.lwd = 2, alpha = 0, size = 0.5) +
	qtm(rect, fill = NULL) +
	tm_layout(outer.margins = c(0.04, 0.04, 0.02, 0.02), frame = FALSE)
```


## Spatial cross-validation

i.e. the fact that points close to each other tend to share similarities compared to points further apart.
Simply put, if it rains at one location it is pretty likely that it also rains if we moved 1 meter in any direction.
But if we moved 10 or 100 km this might not longer be the case. 

- short intro spatial autocorrelation, maybe by showing artificial spatial datasets with different sills, nuggets, ranges (don't show the code but just the concept of spatial autocorrelation)
- spatial cross-validation when predictive performance is desirable 
- use Ecuador landslide data to spatially predict landslide susceptibility (GAM, i.e. a semiparametric extension of a GLM + refer to eco chapter in which we will use ml and where the hyperparameter tuning also requires an additional inner-fold tuning)

@muenchow_geomorphic_2012
@brenning_spatial_2012
@schratz_performance_2018
@james_introduction_2013
@blangiardo_spatial_2015
@zuur_beginners_2017
@zuur_mixed_2009

- What is spatial modeling and for what do we use it?
- What is cross-validation, why do we need it?
- What is spatial cv?

Spatial modeling: species distribution models, landslide susceptibility, epidemiology, disease mapping, rock glaciers, etc.

When we are interested in the accuracy of a model, i.e., when we want to assess a model's predictive performance, we want to avoid overfitting.^[short definition of overfitting]
Spatial autocorrelation will lead to overfitting when the training dataset is not independent of the test dataset which is frequently the case in temporal and spatial settings.

Cross-validation separates test and training datasets randomly.
Let's take our landslide dataset as an example.
Randomly selecting 20% of all points leads to an unwanted effect, namely that test and training points might be close to each other (see Figure ??).
The first law of geography states that points close to each other tend to be, on average, more similar compared to points further apart.
This means these points are not independent.
Hence, using this information in our modeling is like a sneak preview, i.e. using information that should be unavailable to the test dataset.

## Exercises

1. Compute the terrain attributes slope, plan curvature, profile curvature and catchment area from `dem` (provided by `data("landslides", package = "RSAGA")`) with the help of R-GIS bridges, and extract the values from the corresponding output rasters to landslides/non-landslides dataframe.
1. Reproduce the spatial prediction with the derived terrain attribute rasters (see Figure ??).
1. Compute a non-spatial cross-validation and make boxplots to compare the AUROC from a spatial and a non-spatial cv (see also Figure ??).
1. Use the squared slope as a further predictor.
Repeat the modeling. 
How has the spatially cross-validaded mean AUROC value changed compared to the model without the squared altitude predictor?

