# Spatial cross-validation {#spatial-cv}

## Prerequisites {-}

This chapter assumes you have a strong grasp of spatial data analysis and processing, covered in chapters 2-5.
Additionally, we assume that you are familiar with linear regression and its generalized extensions [@zuur_mixed_2009].

We will need following packages:

```{r, message = FALSE} 
library(sf)
library(raster)
library(RQGIS)
library(RSAGA)
library(mlr)
```

- Required data will be downloaded in due course.

## Introduction
In the beginning, we pointed out that there are several programming languages suitable for command-line based geocomputing (section \@ref(software-for-geocomputation)).
The special advantage of doing geocomputation with R is combining geocomputing with R's unparalleled statistical power.
In this chapter we will introduce predictive mapping by means of statistical learning [@james_introduction_2013] while using spatial cross-validation for a bias-reduced assessment of the model performance - something which is probably only easily doable with R at the moment.

Statistical learning aims at understanding data by building models which disentangle underlying relationships (tidyverse figure: model data).
It is used throughout a vast range of disciplines such as economics, physics, medicine, biology, ecology and geography, and can be roughly grouped into supervised and unsupervised techniques [@james_introduction_2013].
In this chapter we will only focus on supervised techniques, i.e., we have a response variable, in our case this will be a binary one (landslide vs. non-landslide) but could be also a numeric (pH value), an integer (species richness) or a categorical variable (land use).
With the advent of big data, statistical learning has even gained in popularity, especially so-called machine learning approaches.
Machine learning tends to be especially useful if the aim is not statistical inference but prediction, e.g., future customer behavior.
Though prediction will be the aim of the modeling in this chapter, we will not use machine learning but a simple generalized linear model (GLM).
This is because a GLM is probably familiar to most readers, and therefore instead of explaining in detail the model building we can focus on the speciality of geographic data in a modeling context and spatial cross-validation.^[Readers who are in need of refreshing their regression skills might have a look at @zuur_mixed_2009.]
Nevertheless, a generalized additive model or a machine learning approach would be more suitable for our dataset (see exercises).
In chapter \@ref(eco) we will build on this chapter and use spatial cross-validation with a machine learning approach.

## Case study: landslide susceptibility {#case-study}

For more details please refer to @muenchow_geomorphic_2012.

```{r, eval = FALSE, echo=FALSE, fig.cap="Landslide initiation points in Southern Ecuador (Projection: UTM zone 17S (EPSG: 32717)."}
library(tmap)
load("extdata/spatialcv.Rdata")
lsl = st_as_sf(lsl, coords = c("x", "y"), crs = 32717)
hs = hillShade(ta$slope * pi / 180, terrain(dem, opt = "aspect"))
rect = tmaptools::bb_sp(hs)
bbx = tmaptools::bb(hs, xlim = c(-0.02, 1), ylim = c(-0.02, 1), relative = TRUE)
# random sample 20%
ind = sample(1:nrow(lsl), round(nrow(lsl) * 0.2))
sam = lsl[ind, ]

tm_shape(hs, bbox = bbx) +
	tm_grid(col = "black", n.x = 1, n.y = 1, labels.inside.frame = FALSE,
	        labels.rot = c(0, 90)) +
	tm_raster(palette = gray(0:100 / 100), n = 100, legend.show = FALSE) +
	tm_shape(dem) +
	tm_raster(alpha = 0.5, palette = terrain.colors(10),
	          auto.palette.mapping = FALSE, legend.show = FALSE) +
	tm_shape(lsl) + 
	tm_bubbles("lslpts", size = 0.5, palette = "-RdYlBu") +
  tm_shape(sam) +
  tm_bubbles(border.col = "gold", border.lwd = 2, alpha = 0, size = 0.5) +
	qtm(rect, fill = NULL) +
	tm_layout(outer.margins = c(0.04, 0.04, 0.02, 0.02), frame = FALSE)
```


## Spatial cross-validation

i.e. the fact that points close to each other tend to share similarities compared to points further apart.
Simply put, if it rains at one location it is pretty likely that it also rains if we moved 1 meter in any direction.
But if we moved 10 or 100 km this might not longer be the case. 


- short intro spatial autocorrelation, maybe by showing artificial spatial datasets with different sills, nuggets, ranges (don't show the code but just the concept of spatial autocorrelation)
- spatial cross-validation when predictive performance is desirable 
- use Ecuador landslide data to spatially predict landslide susceptibility (GAM, i.e. a semiparametric extension of a GLM + refer to eco chapter in which we will use ml and where the hyperparameter tuning also requires an additional inner-fold tuning)

@muenchow_geomorphic_2012
@brenning_spatial_2012
@schratz_performance_2018
@james_introduction_2013
@blangiardo_spatial_2015
@zuur_beginners_2017
@zuur_mixed_2009

- What is spatial modeling and for what do we use it?
- What is cross-validation, why do we need it?
- What is spatial cv?

Spatial modeling: species distribution models, landslide susceptibility, epidemiology, disease mapping, rock glaciers, etc.

When we are interested in the accuracy of a model, i.e., when we want to assess a model's predictive performance, we want to avoid overfitting.^[short definition of overfitting]
Spatial autocorrelation will lead to overfitting when the training dataset is not independent of the test dataset which is frequently the case in temporal and spatial settings.

Cross-validation separates test and training datasets randomly.
Let's take our landslide dataset as an example.
Randomly selecting 20% of all points leads to an unwanted effect, namely that test and training points might be close to each other (see Figure ??).
The first law of geography states that points close to each other tend to be, on average, more similar compared to points further apart.
This means these points are not indepedent.
Hence, using this information in our modeling is like a sneak preview, i.e. using information that should be unavailable to the test dataset.

<!--
Usually people seek to accomplish one of the following aims when using supervised statistical learning techniques: 

1. Spatial prediction of the response variable
2. Inference about the relationship between response and predictors

In the latter case, we need to make sure to comply with all model assumptions (normality, heterogeneity, independence).
Spatial predictions are easier since we can argue that, the predictive performance of a model incorporating a (spatial) correlation structure is on average the same as for a model without a spatial correlation structure.
This is the reason why machine learning techniques (no explicit model assumptions) are so popular when the goal is a good prediction.
-->